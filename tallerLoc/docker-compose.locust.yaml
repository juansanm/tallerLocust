version: '3.8'
services:
  api:
    image: juanfelipe/ml-inference-api:latest
    ports:
      - "8000:8000"
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
      - MODEL_NAME=modelo-prediccion
      - MODEL_STAGE=Production
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
    networks:
      - ml-network
    restart: unless-stopped

networks:
  ml-network:
    driver: bridge